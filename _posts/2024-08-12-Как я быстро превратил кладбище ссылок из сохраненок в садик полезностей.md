---
layout: post
---

<img src="/assets/Media files/мем для статьи.png" alt="drawing" style="width:80%;"/>

Многие не хотят в этом признаваться, но почти у каждого из нас есть одно постыдное удовольствие. Мы создаем огромные хранилища ссылок, закладок и источников в самых невероятных местах. Пару недель назад я провел опрос который только подтвердил опасения - у порядка 70% моих подписчиков есть такая личная мусорка. Мало того что найти в этом хламе что-либо получается редко, так еще и реально полезные источники регулярно теряются.

Я прошел длинный путь от all-in-one инбокса в Evernote через plain-text систему в Obsidian c навешенными плагинами и сейчас использую простое решение с использованием ИИ которое кроме того что экономит массу времени так еще и позволило быстро разобрать старые завалы. Но обо всем по порядку.

<img src="/assets/Media files/Pasted image 20241125133421.png" alt="drawing" style="width:80%;"/>
*Неутешительная статистика*

## Эпоха Evernote

В своей истории управления источниками я сменил несколько систем. И первая из них была GTD-like система с инбоксом в Evernote.

Все входящие, будь то задачи, источники или конкретные кейсы падали в один единственный инбокс, а потом и в какую-нибудь категорию. Конечно это было жутко неэффективно.

Например в категории «Публичные выступления» могло быть более 100 заметок, в которых затерялось 3 источника. Чтобы найти эти источники приходилось перебирать всю категорию.

К тому же там есть много голых ссылок на статьи. А учитывая срок жизни среднего сайта, то через 3-4 года большая часть из них перестает работать и обнуляет мои старания по их сбору.

## Мимолетное увлечение CitAvi

Потом я начал серьезные научные и методические разработки и переехал в менеджер знаний CitAvi. Опыт был непродолжительный и печальный. После того как количество заметок перевалило за тысячи база начала тормозить. А теперь представьте если бы я добавлял все источники отдельными заметками...

## Эпоха Obsidian

<img src="/assets/Pasted image 20241206190902.png" alt="drawing" style="width:80%;"/>

*Граф в Obsidian-е - красиво, но не только лишь все понимают как его использовать*

Последним инструментом был Obsidian. Который я до сих пор использую. В нем мною была разработана система внутри которой была реализована довольно удобная работа с источниками. Основы [описаны](https://nick-senin.github.io/2022/02/02/%D0%A0%D0%B0%D0%B1%D0%BE%D1%82%D0%B0-%D1%81-%D0%B8%D1%81%D1%82%D0%BE%D1%87%D0%BD%D0%B8%D0%BA%D0%B0%D0%BC%D0%B8-%D0%B2-Obsidian.html) здесь.

Благодаря возможностям платформы я мог линковать источники на другие заметки в базе. Через QuickAdd у меня был глобальный хоткей с помощью которого я моментально кидал любую ссылку прямо в заметку-архив.

Но были и минусы которые повлекли за собой пересмотр системы. Во-первых это костыльная поддержка мобилки с кучей гемороя по настройке синхронизации и быстрого добавления. Это привело к активации древнего зла в виде Saved messages в телеграмме. Этот чат я использовал как мобильный инбокс.

Думаю не стоит даже намекать, как часто у меня получалось его разбирать.

Но на самом деле огромная куча источников в обсидиане также генерировала неимоверную прокрастинацию. Недаром существует ряд исследований, показывающих что когда ты видишь неподъемный объем работы, то это увеличивает вредные эффекты от монотонности труда и создает прочие психологические барьеры.

На пике внутри заметки было 4.5 тысяч строк с источниками и лишь часть я разделил по категориям. И это то при наличии быстрого инструмента для категоризации...

По факту такая система превратилась в еще одно кладбище.

## ИИ спасает положение
На данный момент я использую несколько другое решение, которое довольно легко перекрыло все вышеперечисленные недостатки. И на его разработку я потратил где-то часа три.

Ниже я хочу поделиться его механизмом и показать ряд выгодных сценариев использования.

Суть очень проста - на данный момент это бот в телеграмме с подключенной LLM-моделью и табличкой куда улетают все источники.

Вот все что делает бот после того как получает входящее сообщение :
1. Определяет тип входящего сообщения. Тут я взял широко и это может быть : книга, курс, приложение, идея, задача, кейс и еще несколько.
2. Определяет одну или несколько сфер к которым относится сообщение. В основном это общие предметные области которые меня интересуют.
3. Отправляет все это в табличку с фильтрами по типу и сфере. Для этого я использую AirTable.

Для того чтобы бот сработал правильно к голой ссылке нужно добавить небольшой комментарий. Но во многих случаях бот правильно определяет категории даже без ~~слов~~ комментариев.

Довольно быстро я понял что можно сортировать и по несколько источников в одном сообщении что крайне удобно. Суммарно на разработку с учетом отладки промпта я потратил часа три, что делает этот инструмент топовым по соотношению ценность/затраты.

## Как это было сделано
Даже если развитие ИИ остановится на сегодняшнем уровне то, на мой взгляд, очень мало кто приблизился к использованию хотя бы 70% его потенциала в своей работе. По разным причинам.

Например, многие думают что железка должна сама все сделать, прочитать наши мысли, и т. п. Без навыков работы с промптами и цепочками промптов эффективность получаемых инструментов сииильно ниже.

В целом промпт для описанного выше инструмента простой и понятный. Но я и сам долго не подозревал насколько он неэффективен пока не начал их отлаживать на больших тестовых сетах. Для этого можно использовать **Promptfoo** или **Langsmith**. Благо, имея свой файл на 4500 источников, проблем с созданием тестового сета не возникло.

После такой отладки доля правильных ответов возрастает на десятки процентов. И в целом можно даже использовать дешевые модели вроде gpt-4o-mini. Но я все равно использую топ-тиер, так как они чуууть лучше.

## Какую модель лучше всего использовать

Несмотря на то что модели от OpenAI почти всегда находятся в топах, их конкуренты не перестают удивлять. Например, для кодинга я использую почти только модели от Anthropic. Плюс недавно вышла относительно маленькая Qwen Coder 2.5 которая сопоставима с лучшими моделями для кодинга.

Поэтому в своих проектах я не использую одну "лучшую" модель, а нахожу ту, что лучше всего подходит под задачу. И париться с кучей подписок я не хочу. Поэтому использую [сервисы batch-API](https://vsegpt.ru/?cmpad=p5595965148), которые предоставляют доступ к огромному количеству разных моделей под разные задачи.

<img src="/assets/Media files/Pasted image 20240813150016.png" alt="drawing" style="width:80%;"/>
*К тому же эта "лучшая" модель постоянно меняется*

А теперь давайте я покажу несколько вкусных юзкейсов.

## Так какой у тебя промпт?
Ниже я разберу первую половину промпта которая определяет тип входящих источников. Поехали!

> Your task is to break each message into blocks. Each block has one of the following types :

Поясняю что в сообщении может быть несколько источников. 

> Type : YouTube видео  
> Type : Пример VIKENT.RU
> Type : Он-лайн статья 
> Type : Пример Livrezon
> Type : На вычитку/поиск 
> Type : Ссылка libgen/архив Анны
> Type : Книга
> Type : Приложение или полезный ресурс
> Type : Остальное

Явно перечисляю типы входящих. Эта часть промпта работает даже без дополнительных пояснений по каждому типу. Названия практически всегда достаточно.   

> Based on this data, create an array of sources. Each element of the array should have a name - this is the content of the block itself ,exactly as it was given, and its type, which you need to define. 

Говорю что нужно создать массив источников и что в этом массиве должно содержаться. 

> The block name must contain both the URL and all comments.

Уточняю что все входящие комментарии и url-ы должны попадать в массив без изменений, наряду с определенным типом. 

> Then transfer this array to airtable.

Здесь использую tool call. Т. е. модель понимает что я вызвал заранее определенный инструмент для пересылки массива в airtable посредством вебхука. В этом примере я реализовал этот инструмент через платформу [coze.com](https://www.coze.com/home). 

<img src="/assets/Media files/Pasted image 20241204164836.png" alt="drawing" style="width:80%;"/>

Замечу что не все модели поддерживают tool calling. В сервисе vsegpt такие модели, например, помечены специальным бейджем. [Вот здесь](https://vsegpt.ru/Docs/API?cmpad=p5595965148) в разделе "Поддержка tools" более подробно описано. 

## Юзкейсы
### Работа с подходящим типом источников
Группировка по разным типам входящих позволяет вытаскивать источники в зависимости от контекста. Например, если я куда-нибудь еду и могу послушать видео то могу сделать фильтр по видео и т. п.

Этот подход может развиться во [что-то такое](https://nick-senin.github.io/2021/12/19/%D0%98%D1%89%D0%B5%D0%BC-%D0%B4%D0%BE%D0%BF%D0%BE%D0%BB%D0%BD%D0%B8%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5-%D0%B2%D0%BE%D0%B7%D0%BC%D0%BE%D0%B6%D0%BD%D0%BE%D1%81%D1%82%D0%B8-%D0%B4%D0%BB%D1%8F-%D1%80%D0%B0%D0%B7%D0%B2%D0%B8%D1%82%D0%B8%D1%8F-%D0%BD%D0%B0%D0%B2%D1%8B%D0%BA%D0%BE%D0%B2-%D0%B8-%D0%BF%D1%80%D0%B8%D0%B2%D1%8B%D1%87%D0%B5%D0%BA.html).

Если же выделить приложения - можно быстро получить список полезных приложений, причем с учетом нужной сферы.

### Фильтр по сфере
Ну и само собой можно делать фильтр по сфере отдельно. Скажем, я хочу улучшить свою сферу здоровья. Сделав фильтр по сфере получаю нужный список источников. Нужное добавляю в базу и реализую.

### Разбор авгиевых конюшен
Так как бот "кушает" несколько источников одновременно, то это позволяет закидывать пачками куски кладбища ссылок и подобного. На выходе получается структурированная таблица.

Но это не все возможности которые предоставляет массовое закидывание.

### Молниеносная библиография
Представьте, что вы прочитали очень хорошую научную статью. И там есть ссылки на еще 10 интересных научных статей. И эти статьи могут относиться к разным сферам.

Сколько времени вы будете добавлять их в свой библиографический менеджер(оптимистично представим)?

Наверное не те несколько секунд которые будут затрачены при использовании вышеописанного бота. Причем даже без особых комментариев, потому как по названию ботом почти всегда правильно определяется целевая сфера. А тип будет определен как научная статья просто по формату ссылки.

## Основные выводы
1. Современный ИИ часто позволяет создавать за 1-2 часа крайне полезные инструменты которые будут эффективно встраиваться в ваши рабочие процессы.  
2. Во многих случаях от завалов ссылок и источников просто нужно отказаться, но если же вы реально их используете, то вышеописанный инструмент сэкономит не один час в неделю. 
3. при использовании LLM я рекомендую : использовать одну или [несколько моделей](https://vsegpt.ru/Docs/ModelsNew?cmpad=p5595965148) которые наилучшим образом подходят под задачу/подзадачи, отлаживать промпты сразу на больших тестовых сетах.

Если захотите больше узнать про повышение продуктивности, подписывайтесь на мой telegram-канал [Пределы Профессионализма](https://t.me/prof_limits)


